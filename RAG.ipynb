{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. INSTALACIÓN Y CARGA DE DEPENDENCIAS\n!pip install transformers sentence-transformers accelerate bitsandbytes numpy pandas pyarrow datasets torch faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T20:38:30.856750Z","iopub.execute_input":"2025-11-23T20:38:30.857036Z","iopub.status.idle":"2025-11-23T20:39:56.873158Z","shell.execute_reply.started":"2025-11-23T20:38:30.857006Z","shell.execute_reply":"2025-11-23T20:39:56.872167Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.9.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (19.0.1)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.4.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.1.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nCollecting pyarrow\n  Downloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.6.0)\nRequirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.18)\nRequirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0->datasets) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\nDownloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pyarrow-22.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (47.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyarrow, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, faiss-cpu, bitsandbytes\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 19.0.1\n    Uninstalling pyarrow-19.0.1:\n      Successfully uninstalled pyarrow-19.0.1\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.48.2 faiss-cpu-1.13.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pyarrow-22.0.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ==============================================================================\n# 1. DEPENDENCIAS Y LIBRERÍAS\n# ==============================================================================\nimport pandas as pd\nimport numpy as np\nimport torch\nimport faiss\nfrom datasets import load_dataset\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Ignorar warnings de tokenizers y modelos\n\n\n# ==============================================================================\n# 2. CARGA Y PROCESAMIENTO DEL CORPUS (Usando solo la Cover Letter)\n# ==============================================================================\ndef cargar_corpus():\n    print(\"--- 1. Cargando Dataset y Corpus ---\")\n    try:\n        ds = load_dataset(\"dhruvvaidh/cover-letter-dataset-llama3\")\n        train_df = ds[\"train\"].to_pandas()\n    except Exception as e:\n        print(f\"Error cargando dataset: {e}. Usando datos dummy para demostración.\")\n        train_df = pd.DataFrame({\n            \"Instruction\": [\"I1\", \"I2\"],\n            \"Prompt\": [\"Job: Python Dev. Candidate: Expert in Django...\", \"Job: Data Scientist. Candidate: Expert in Pandas...\"],\n            \"Output\": [\"Dear Hiring Manager, my skills in Python and Django make me a perfect fit for this role...\", \"To Whom It May Concern, I have a strong background in data science and deep learning...\"]\n        })\n\n    def canonize_row(r):\n        output = str(r.get(\"Output\", \"\")).strip()\n        return {\n            \"doc_id\": r.name,\n            \"text_for_rag\": output,\n        }\n\n    corpus_df = train_df.apply(canonize_row, axis=1, result_type=\"expand\")\n    corpus_list = corpus_df.to_dict('records')\n    textos_para_indexar = corpus_df['text_for_rag'].tolist()\n    \n    print(f\"Corpus cargado: {len(corpus_list)} documentos.\")\n    return corpus_list, textos_para_indexar\n\ncorpus_list, textos_para_indexar = cargar_corpus()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T20:44:50.268552Z","iopub.execute_input":"2025-11-23T20:44:50.269355Z","iopub.status.idle":"2025-11-23T20:44:51.222274Z","shell.execute_reply.started":"2025-11-23T20:44:50.269326Z","shell.execute_reply":"2025-11-23T20:44:51.221460Z"}},"outputs":[{"name":"stdout","text":"--- 1. Cargando Dataset y Corpus ---\nCorpus cargado: 813 documentos.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ==============================================================================\n# 3. INDEXACIÓN (BGE + FAISS CPU) \n# ==============================================================================\nprint(\"\\n--- 2. Generando Embeddings e Índice FAISS (BGE) ---\")\nEMBED_MODEL_ID = \"BAAI/bge-large-en-v1.5\"\ntry:\n    embedder = SentenceTransformer(EMBED_MODEL_ID)\n    doc_embeddings = embedder.encode(\n        textos_para_indexar, \n        batch_size=32, \n        show_progress_bar=True, \n        normalize_embeddings=True\n    )\n    doc_embeddings = np.array(doc_embeddings, dtype=\"float32\")\n    d_dimension = doc_embeddings.shape[1]\n\n    index = faiss.IndexFlatIP(d_dimension)\n    index.add(doc_embeddings)\n    print(f\"Índice FAISS creado en CPU con {index.ntotal} vectores.\")\n\nexcept Exception as e:\n    print(f\"Error crítico en embeddings/FAISS. {e}\")\n    embedder = None\n    index = None\n\n# ==============================================================================\n# 4. FUNCIÓN DE BÚSQUEDA (RETRIEVER) \n# ==============================================================================\ndef buscar_candidatos(query, k=3):\n    if index is None or embedder is None:\n        return []\n    \n    q_text = \"Represent this sentence for searching relevant passages: \" + query\n    \n    q_emb = embedder.encode([q_text], normalize_embeddings=True)\n    q_emb = np.array(q_emb, dtype=\"float32\")\n    \n    scores, indices = index.search(q_emb, k)\n    \n    resultados = []\n    for idx, score in zip(indices[0], scores[0]):\n        if idx != -1:\n            doc_data = corpus_list[idx]\n            resultados.append({\n                \"id\": doc_data['doc_id'],\n                \"score\": float(score),\n                \"context\": doc_data['text_for_rag'], # Cover Letter completa\n            })\n    return resultados","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T20:44:52.627690Z","iopub.execute_input":"2025-11-23T20:44:52.627970Z","iopub.status.idle":"2025-11-23T20:45:08.875576Z","shell.execute_reply.started":"2025-11-23T20:44:52.627948Z","shell.execute_reply":"2025-11-23T20:45:08.874745Z"}},"outputs":[{"name":"stdout","text":"\n--- 2. Generando Embeddings e Índice FAISS (BGE) ---\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/26 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56163a820f2945dbbf9dc98ad4850f14"}},"metadata":{}},{"name":"stdout","text":"Índice FAISS creado en CPU con 813 vectores.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ==============================================================================\n# 5. CONFIGURACIÓN DEL GENERATOR (LLM para Ranking) \n# ==============================================================================\nLLM_ID = \"Qwen/Qwen2.5-3B\"\nprint(f\"\\n--- 3. Cargando LLM Generador: {LLM_ID} (Contexto 128K tokens) ---\")\n\ntry:\n    # Configuración de 4 bits para ahorrar memoria\n    quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n\n    tokenizer = AutoTokenizer.from_pretrained(LLM_ID)\n    llm_model = AutoModelForCausalLM.from_pretrained(\n        LLM_ID,\n        quantization_config=quantization_config,\n        device_map=\"auto\"\n    )\n    \n    # Configuración del tokenizer para generación causal\n    tokenizer.pad_token = tokenizer.eos_token \n    tokenizer.padding_side = \"left\" \n\n    ranker_pipeline = pipeline(\n        \"text-generation\", \n        model=llm_model,\n        tokenizer=tokenizer,\n        device_map=\"auto\"\n    )\n    \n    print(\"LLM cargado correctamente en memoria reducida (4-bit).\")\nexcept Exception as e:\n    print(f\"Error cargando LLM o libs de cuantización (bitsandbytes/accelerate). {e}\")\n    ranker_pipeline = None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T20:50:52.832403Z","iopub.execute_input":"2025-11-23T20:50:52.832697Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generar_ranking_llm(job_offer, candidatos):\n    \"\"\"Genera un ranking usando Qwen2.5-3B usando la plantilla de chat correcta.\"\"\"\n    \n    global ranker_pipeline\n    if not ranker_pipeline:\n        return \"Error: LLM no disponible.\"\n    \n    # 1. Construir el texto de los candidatos\n    contexto_str = \"\"\n    for i, c in enumerate(candidatos, 1):\n        perfil = c['context'].replace(\"\\n\", \" \").strip()\n        contexto_str += f\"CANDIDATE {i} (ID {c['id']}) - COVER LETTER: {perfil}\\n\\n\"\n    \n    \n    # 2. Definición de mensajes con Prompt Engineering avanzado\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"You are an expert  Technical Recruiter. Your job is to evaluate candidates based strictly \"\n                    \"on how well their application matches the provided Job Description. \"\n                    \"You must provide critical reasoning, not just a summary and explain your decission in 3-5 lines.\"\n                )\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"\"\"\n    ### JOB DESCRIPTION:\n    {job_offer}\n    \n    ### CANDIDATES TO EVALUATE:\n    {contexto_str}\n    \n    ### YOUR TASK:\n    Rank the candidates from Best Fit (1) to Worst Fit.\n    \n    ### REQUIRED OUTPUT FORMAT:\n    For each candidate, you must use exactly this format:\n    \n    1. **Candidate ID [ID]**: [Best/Good/Weak] Match\n       - **Reasoning**: [Explain specifically WHY. Mention specific skills from their letter that match the job (e.g., \"Has 5 years in Python\", \"Mentions AWS\"). Mention missing skills if any.]\n    \n    2. **Candidate ID [ID]**: ...\n    \n    (Do NOT copy the full cover letter. Only provide the ranking and the reasoning).\n    \"\"\"\n            }\n        ]\n    \n        # 3. Aplicar plantilla de chat\n        prompt = ranker_pipeline.tokenizer.apply_chat_template(\n            messages, \n            tokenize=False, \n            add_generation_prompt=True\n        )\n        \n        # 4. Generación\n        outputs = ranker_pipeline(\n            prompt, \n            max_new_tokens=500,  # Damos espacio para que se explique\n            temperature=0.2,     # Temperatura baja para ser más analítico y menos creativo\n            do_sample=True,\n            return_full_text=False\n        )\n        \n        return outputs[0]['generated_text'].strip()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T21:00:50.245745Z","iopub.execute_input":"2025-11-23T21:00:50.246043Z","iopub.status.idle":"2025-11-23T21:00:50.253002Z","shell.execute_reply.started":"2025-11-23T21:00:50.246021Z","shell.execute_reply":"2025-11-23T21:00:50.252190Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# ==============================================================================\n# 7. FUNCIÓN RAG COMPLETA AUTOMATIZADA \n# ==============================================================================\ndef ejecutar_rag_pipeline(job_offer_query, k=3):\n    \"\"\"\n    Ejecuta el pipeline RAG completo para encontrar y rankear candidatos.\n\n    Args:\n        job_offer_query (str): La nueva oferta de trabajo.\n        k (int): Número de candidatos a recuperar (Top-K).\n\n    Returns:\n        dict: Contiene el ranking generado por el LLM.\n    \"\"\"\n    print(f\"\\n{'='*60}\")\n    print(f\"INICIANDO RAG para: {job_offer_query}\")\n    print(f\"Buscando los {k} mejores candidatos (usando Cover Letters completas)...\")\n    print(f\"{'='*60}\")\n\n    # 1. RECUPERACIÓN (Retrieval - BGE + FAISS)\n    candidatos_encontrados = buscar_candidatos(job_offer_query, k=k)\n\n    if not candidatos_encontrados:\n        print(\"\\n No se encontraron candidatos relevantes. Terminando el pipeline.\")\n        return { \"ranking_final_llm\": \"No se encontraron candidatos para rankear.\" }\n\n    print(\"\\n[FASE 1: RECUPERACIÓN COMPLETADA]\")\n    for i, c in enumerate(candidatos_encontrados, 1):\n        print(f\"  {i}. Candidato ID: {c['id']} | Similitud BGE: {c['score']:.4f}\")\n\n    # 2. RANKING/GENERACIÓN (Generation - Qwen2.5-3B)\n    print(f\"\\n{'-'*60}\")\n    print(\"INICIANDO FASE DE RANKING (LLM)...\")\n    \n    ranking_generado = generar_ranking_llm(job_offer_query, candidatos_encontrados)\n    \n    print(f\"{'-'*60}\")\n    print(\"REPORTE FINAL DE RR.HH:\")\n    print(ranking_generado)\n\n    return { \"ranking_final_llm\": ranking_generado }\n\n# ==============================================================================\n# 8. EJEMPLO DE USO\n# ==============================================================================\nTARGET_JOB = \"We need a Project Manager with PMP certification, strong leadership, experience in transformer-based models, Python, and cloud\"\nejecutar_rag_pipeline(TARGET_JOB, k=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T21:00:51.731520Z","iopub.execute_input":"2025-11-23T21:00:51.731874Z","iopub.status.idle":"2025-11-23T21:01:02.452136Z","shell.execute_reply.started":"2025-11-23T21:00:51.731847Z","shell.execute_reply":"2025-11-23T21:01:02.451388Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nINICIANDO RAG para: We need a Project Manager with PMP certification, strong leadership, experience in transformer-based models, Python, and cloud\nBuscando los 3 mejores candidatos (usando Cover Letters completas)...\n============================================================\n\n[FASE 1: RECUPERACIÓN COMPLETADA]\n  1. Candidato ID: 811 | Similitud BGE: 0.6717\n  2. Candidato ID: 712 | Similitud BGE: 0.6603\n  3. Candidato ID: 214 | Similitud BGE: 0.6597\n\n------------------------------------------------------------\nINICIANDO FASE DE RANKING (LLM)...\n------------------------------------------------------------\nREPORTE FINAL DE RR.HH:\nCandidate 1 (ID 811): Best Match\nReasoning: Candidate 811 has a strong background in data analysis and project management, which aligns with the requirements of the job description. Additionally, their experience in transformer-based models, Python, and cloud aligns with the job requirements. Their cover letter also mentions their PMP certification, which is a strong indicator of their project management skills. They also mention their collaboration with cross-functional teams, which is a key aspect of the job. Their communication and problem-solving skills are also mentioned, which are important for the job. Overall, their cover letter shows that they have the necessary skills and experience for the job.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'ranking_final_llm': 'Candidate 1 (ID 811): Best Match\\nReasoning: Candidate 811 has a strong background in data analysis and project management, which aligns with the requirements of the job description. Additionally, their experience in transformer-based models, Python, and cloud aligns with the job requirements. Their cover letter also mentions their PMP certification, which is a strong indicator of their project management skills. They also mention their collaboration with cross-functional teams, which is a key aspect of the job. Their communication and problem-solving skills are also mentioned, which are important for the job. Overall, their cover letter shows that they have the necessary skills and experience for the job.'}"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}